# 内容推荐

## 用户画像的“能”与“不能”
- 用户画像：User Profile
- 用户画像应该给机器看，而不是给人看的。
- 用户向量化后的结果，就是User Profile，俗称“用户画像”。所以，用户画像不是推荐系统的目的，而是在构建推荐系统的过程中产生的一个关键环节的副产品。
- 建立用户画像的关键因素：维度和量化。要根据使用效果（排序好坏、召回覆盖等指标）来知道用户画像的量化
- 用户画像构建方法
    - 查户口，使用原始数据，如人口统计学信息、购买历史、阅读历史
    - 堆数据，做统计，如兴趣标签
    - 黑盒子，用机器学习方法学习特征，比如使用潜语义模型构建用户阅读兴趣，使用矩阵分解得到的隐因子，使用深度学习模型学习用户的Embedding向量。


## 从文本到用户画像


## 超越标签的内容推荐系统
基于内容推荐的框架图
- 内容源
- 内容分析和用户分析，产生结构化内容库和内容模型，也就是物品画像，在结合用户行为数据，经过用户分析得到用户画像。
- 内容推荐算法
    - 简单的算法为计算用户和内容所对应的向量相似性
    - 收集某种行为日志，转换成训练样本（一部分是特征，包括用户画像，物品画像，上下文信息等，另一部分是用户行为，作为标注信息，如点击、收藏、转发），训练预估模型（二分类器），常用算法如LR和GBDT


# 近邻推荐

## 协同过滤
- 基于记忆的协同过滤（Memory-Based）/基于近邻的协同过滤算法
    - 基于用户的协同过滤算法（user-based collaboratIve filtering）
        - 用户向量，向量的维度是物品个数，向量是稀疏的，取值为0或1
        - 两两计算用户之间的相似度
        - 为每个用户产生推荐结果，加权求和
    - 基于物品的协同过滤算法（item-based collaborative filtering）
        - 物品向量，向量的维度是用户个数，向量是稀疏的，取值为用户对这个物品的消费结果（行为本身或行为量化后的结果如时间长短、次数、费用）
        - 两两计算用户之间的相似度
        - 产生推荐结果，一种是为某个物品推荐相关物品，另一种是给用户推荐“猜你喜欢”的结果（Top K推荐）
- 基于模型的协同过滤（Model-Based）
    - Aspect Model，pLSA，LDA，聚类，SVD，Matrix Factorization等，这种方法训练过程比较长，但是训练完成后，推荐过程比较快。


### 基于用户的协同过滤算法
- 稀疏矩阵的构造方式，有CSR（数值、列号和行偏移共同编码），COO（行号、列号、数值）
- 降低相似度计算复杂度
    - 对向量采样计算，DIMSUM算法
    - 向量化计算
- 降低两两计算相似度的复杂度，使用MapReduce方式
- 降低计算物品推荐分数的复杂度，使用MapReduce方式

### 基于物品的协同过滤算法
- 物品数量往往小于用户数量；物品间的相似度比较静态，变化速度没有用户快；物品对应的消费者数量巨大，计算物品间的相似度好于计算用户间的。
- 改进物品相似度计算
    - 物品中心化，减去物品分数的均值，去掉物品中铁杆粉丝群体的非理性因素
    - 用户中心化，减去对应用户分数的均值，去掉用户的主观成分，保留偏好
- 产生推荐结果的两种应用场景
    - Top K推荐，汇总和“用户已经消费过的物品相似”的物品，按照汇总后的分数去Top K
    - 相关推荐，[Slope One算法](https://blog.csdn.net/redhatforyou/article/details/86656356)

## 协同过滤中相似度计算方法
- 欧式距离
- 余弦相似度
- 皮尔逊相似度
- 杰卡德相似度，适用于隐式反馈数据，布尔向量

## 近邻推荐的问题
- 物品之间存在相关性，信息量并不随着向量维度增加而线性增加
- 矩阵元素稀疏，计算结果不稳定，增减一个向量维度，导致近邻结果差异很大的情况存在


# 矩阵分解

[从理论到实战，一篇文章掌握推荐系统之矩阵分解](https://www.sohu.com/a/190681269_470008)

# 模型融合
> 推荐系统在技术实现上一般分为三个阶段：挖掘、召回、排序。挖掘的工作就是对用户和物品做非常深入的结构化分析，建好索引，供召回阶段使用。召回就是通过不同的推荐算法产生不同的推荐结果以及相应的分数。最后针对筛选出的一部分结果做统一的排序，推荐给用户，这个过程也叫做模型融合。

## 经典模型融合方法：线性模型和GBDT组合
- CTR预估就是在推荐一个物品之前，预估一下用户点击它的概率有多大，再根据这个预估的点击率对物品排序输出。
- 逻辑回归属于线性模型，处理不了非线性组合特征，需要引入特征工程。
- 每条样本（将用户、物品、场景三类特征拼到一起），经过N棵GBDT树各自预测一下，给出0或1的结果，再将这N个结果作为一个向量送入LR模型中，产生最终的融合预估结果。也可以在输入特征中加入各个召回模型产生的分数。

## 因子分解机模型（Factorization Machine）

$$
\hat{y} = w_0+\sum_{i=1}^n w_i x_i + \sum_{i=1}^n \sum_{j=i+1}^n <V_i, V_j> x_i x_j
$$
$$
Loss = - \frac{1}{m}  \sum_{i=1}^n [y^{(i)}\log(\sigma(\hat{y})) + (1-y^{(i)}) \log(1- \sigma(\hat{y})) ]
$$

可以变形成矩阵分解模型

## FFM

$$
\hat{y} = w_0+\sum_{i=1}^n w_i x_i + \sum_{i=1}^n \sum_{j=i+1}^n <V_{i,fj}, V_{j,fi}> x_i x_j
$$



## 深度和宽度兼具的融合模型

- CTR预估中的C可以是产品中的任何行为，视频是不是会看完，看完后是不是会收藏，是不是会分享到第三方平台，查看的商品是不是会购买等。
- CTR预估的常见做法就是广义线性模型，然后采用特征海洋战术，挖掘新特征、挖掘特征组合、寻找新的特征离散方法。
    - 线性模型简单，其训练和预测计算复杂度相对低
    - 工程师的精力可以集中在发掘新的有效特征上，俗称特征工程
    - 工程师们可以并行化工作，各自挖掘特征
    - 线性模型的可解释性好
- 深度模型的泛华强于线性模型，但可解释性不好
- Wide & Deep模型，2016年Google Play应用商店上实践检验过的CTR预估方法
    - 深宽模型是一个结合了传统线性模型和深度模型的工程创新
    - 适合高维稀疏特征的推荐场景，稀疏特征的可解释性加上深度模型的泛化性能
    - 为了提高模型的训练效率，用上一次模型参数来初始化当前模型的参数
    - 将类别型特征先做嵌入学习，再将嵌入稠密向量送入深度模型中